{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ee82a8",
   "metadata": {},
   "source": [
    "### Q1. What is Bayes' theorem?\n",
    "\n",
    "Bayes' theorem is a mathematical formula that describes how to update our beliefs about the probability of an event based on new evidence or information. It is named after the Reverend Thomas Bayes, an 18th-century British statistician and theologian who first proposed the theorem.\n",
    "\n",
    "The formula states that the probability of an event A, given some evidence E, is proportional to the probability of the evidence given the event, multiplied by the prior probability of the event, divided by the prior probability of the evidence:\n",
    "\n",
    "P(A | E) = P(E | A) * P(A) / P(E)\n",
    "\n",
    "where P(A | E) is the posterior probability of event A given evidence E, P(E | A) is the probability of the evidence E given event A, P(A) is the prior probability of event A, and P(E) is the prior probability of the evidence.\n",
    "\n",
    "In simpler terms, Bayes' theorem tells us how to update our beliefs about the likelihood of an event based on new information. It is widely used in fields such as statistics, machine learning, and artificial intelligence to make predictions and decisions based on uncertain data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3527e355",
   "metadata": {},
   "source": [
    "### Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "The formula for Bayes' theorem is:\n",
    "\n",
    "P(A | E) = P(E | A) * P(A) / P(E)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A | E) is the posterior probability of event A given evidence E.\n",
    "P(E | A) is the probability of the evidence E given event A.\n",
    "P(A) is the prior probability of event A.\n",
    "P(E) is the prior probability of the evidence.\n",
    "In simple terms, Bayes' theorem helps to update our beliefs about the probability of an event A, given some new evidence E. It does so by multiplying the prior probability of A by the likelihood of the evidence E given A, and dividing by the probability of the evidence E."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8021419",
   "metadata": {},
   "source": [
    "### Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "Bayes' theorem is used in practice in a wide range of fields, including statistics, machine learning, natural language processing, and artificial intelligence, to name a few. Here are some examples of how Bayes' theorem can be applied:\n",
    "\n",
    "1. Spam filtering: Bayes' theorem can be used in email spam filters to determine the probability that an incoming message is spam. The filter calculates the probability that the words and phrases in the message are associated with spam, based on prior training data, and updates the probability based on the content of the new message.\n",
    "\n",
    "2. Medical diagnosis: Bayes' theorem can be used in medical diagnosis to estimate the probability that a patient has a particular disease, given their symptoms and medical history. The prior probability of the disease is based on the prevalence of the disease in the population, and the likelihood of the symptoms given the disease is estimated from medical studies.\n",
    "\n",
    "3. Image recognition: Bayes' theorem can be used in image recognition to classify an image into different categories. The probability of each category is estimated based on prior training data, and the probability of the features in the image given each category is calculated using statistical models.\n",
    "\n",
    "4. Natural language processing: Bayes' theorem can be used in natural language processing to determine the probability that a particular sequence of words is grammatically correct or meaningful. The prior probability of the sentence structure is estimated based on prior training data, and the probability of each word given the sentence structure is calculated using statistical models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61868f28",
   "metadata": {},
   "source": [
    "### Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Bayes' theorem and conditional probability are closely related concepts in probability theory.\n",
    "\n",
    "Conditional probability is the probability of an event A given that another event B has occurred. It is denoted as P(A | B) and is calculated as the probability of both A and B occurring, divided by the probability of B occurring:\n",
    "\n",
    "P(A | B) = P(A and B) / P(B)\n",
    "\n",
    "Bayes' theorem is a formula that relates conditional probabilities to each other. Specifically, it tells us how to update our beliefs about the probability of an event A, given some new evidence B.\n",
    "\n",
    "Bayes' theorem can be derived from conditional probability by multiplying both sides of the equation P(A | B) = P(A and B) / P(B) by P(B) and rearranging the terms, as follows:\n",
    "\n",
    "P(A and B) = P(B | A) * P(A) (using the definition of conditional probability)\n",
    "P(B) = P(B | A) * P(A) + P(B | not A) * P(not A) (using the law of total probability)\n",
    "\n",
    "Substituting these equations into the original formula gives:\n",
    "\n",
    "P(A | B) = P(B | A) * P(A) / (P(B | A) * P(A) + P(B | not A) * P(not A))\n",
    "\n",
    "This is the formula for Bayes' theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f0eeca",
   "metadata": {},
   "source": [
    "### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "Choosing the appropriate type of Naive Bayes classifier for a given problem involves selecting the best fit for the data and the specific characteristics of the problem at hand. Here are some guidelines to consider:\n",
    "\n",
    "1. Gaussian Naive Bayes: This classifier is best suited for continuous data that follows a Gaussian (normal) distribution. It assumes that the probability density function for each class is Gaussian, and estimates the mean and variance for each feature in each class. It is commonly used for data with continuous features, such as sensor data or financial data.\n",
    "\n",
    "2. Multinomial Naive Bayes: This classifier is best suited for discrete data that represents count frequencies, such as word frequencies in text documents or categorical data in survey responses. It assumes that the probability of each feature given a class follows a multinomial distribution, and estimates the probability of each feature for each class.\n",
    "\n",
    "3. Bernoulli Naive Bayes: This classifier is similar to the multinomial Naive Bayes, but is best suited for binary data, where each feature is either present or absent. It assumes that the probability of each feature given a class follows a Bernoulli distribution, and estimates the probability of each feature being present or absent for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb255d",
   "metadata": {},
   "source": [
    "### Q6. Assignment: \n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "\n",
    "    Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "    A       3    3    4    4    3    3    3\n",
    "    B       2    2    1    2    2    2    3\n",
    "    \n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd2e20",
   "metadata": {},
   "source": [
    "To predict the class of a new instance with features X1=3 and X2=4, we can use the Naive Bayes classifier with the following steps:\n",
    "\n",
    "* Step 1: Calculate the prior probabilities of each class, assuming equal prior probabilities for each class:\n",
    "P(A) = P(B) = 1/2\n",
    "\n",
    "* Step 2: Calculate the conditional probabilities of each feature given each class:\n",
    "\n",
    "P(X1=3|A) = 4/10\n",
    "\n",
    "P(X2=4|A) = 3/10\n",
    "\n",
    "P(X1=3|B) = 1/7\n",
    "\n",
    "P(X2=4|B) = 1/7\n",
    "\n",
    "\n",
    "* Step 3: Calculate the joint probabilities of each class and the new instance:\n",
    "\n",
    "P(A,X1=3,X2=4) = P(A) * P(X1=3|A) * P(X2=4|A) = (1/2) * (4/10) * (3/10) = 6/100\n",
    "\n",
    "P(B,X1=3,X2=4) = P(B) * P(X1=3|B) * P(X2=4|B) = (1/2) * (1/7) * (1/7) = 1/98\n",
    "\n",
    "* Step 4: Compare the joint probabilities and select the class with the highest probability:\n",
    "\n",
    "P(A,X1=3,X2=4) > P(B,X1=3,X2=4),\n",
    "\n",
    "so the Naive Bayes classifier would predict that the new instance belongs to class A.\n",
    "\n",
    "Therefore, the Naive Bayes classifier would predict that the new instance with features X1=3 and X2=4 belongs to class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f975be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
