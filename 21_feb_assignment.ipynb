{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7584992d",
   "metadata": {},
   "source": [
    "### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "Web scraping is the automated process of extracting data from websites using software tools. It involves using programs or scripts to crawl web pages and extract useful information, such as product prices, contact details, or reviews. This data can then be stored, analyzed, and used for various purposes.\n",
    "\n",
    "Web scraping is used for a variety of reasons, including market research, data analysis, and lead generation. It is also used to monitor competitor activities, track website changes, and extract data for machine learning models.\n",
    "\n",
    "Three areas where web scraping is commonly used include:\n",
    "\n",
    "1. E-commerce: Web scraping is often used in the e-commerce industry to monitor competitor prices and products, extract product reviews, and analyze consumer behavior.\n",
    "\n",
    "2. Marketing and Sales: Web scraping can be used to extract contact details of potential leads, such as email addresses and phone numbers, to improve sales and marketing efforts.\n",
    "\n",
    "3. Research: Researchers use web scraping to gather data for their studies, including social media data, news articles, and scientific publications. This data can then be analyzed to identify trends and patterns, and to draw conclusions.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e8e7af",
   "metadata": {},
   "source": [
    "### Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "1. Writing custom code: This involves writing code in a programming language such as Python or Ruby to scrape web pages. It allows for more customization and flexibility but requires programming knowledge.\n",
    "\n",
    "2. Using web scraping tools: There are several web scraping tools available, such as BeautifulSoup, Scrapy, and Selenium, which make it easier to extract data from web pages without writing custom code.\n",
    "\n",
    "3. Application programming interface (API) scraping: Some websites offer APIs that allow developers to access their data. This method involves sending requests to the API and receiving the data in a structured format.\n",
    "\n",
    "4. Parsing HTML: This method involves parsing the HTML code of a web page to extract the desired data. It requires knowledge of HTML and can be time-consuming.\n",
    "\n",
    "5. Browser extension: Some browser extensions, such as Data Miner and Web Scraper, can be used to extract data from web pages. These extensions can be used by non-programmers and are relatively easy to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351de40e",
   "metadata": {},
   "source": [
    "### Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Beautiful Soup is a Python library used for web scraping purposes. It is a popular parsing library that allows developers to extract data from HTML and XML files. Beautiful Soup makes it easier to navigate and search the tree-like structure of HTML documents and provides a simple API for extracting information.\n",
    "\n",
    "Beautiful Soup is used for web scraping because it simplifies the process of parsing HTML and XML files. It allows developers to extract data from complex documents quickly and easily. Beautiful Soup is also flexible and can be used to parse documents from a variety of sources, including local files and URLs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc257d",
   "metadata": {},
   "source": [
    "### Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "Flask is a lightweight web framework that is commonly used in web scraping projects because of its simplicity and ease of use. Flask allows developers to build web applications quickly and easily, making it a popular choice for creating web scraping applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd453a24",
   "metadata": {},
   "source": [
    "### Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "1. CodePipeline - AWS CodePipeline is a continuous delivery service that allows developers to automate their software release process. It provides a way to build, test, and deploy code changes automatically.\n",
    "\n",
    "2. Elastic Beanstalk - AWS Elastic Beanstalk is a fully managed service that makes it easy to deploy and scale web applications. It provides a platform for deploying and managing web applications, handling deployment, scaling, and monitoring automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85e7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
